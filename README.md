# ğŸ§  Mini Offline Assistant

**Mini Offline Assistant** is a lightweight, privacy-first AI tool that works completely offline. Powered by a fine-tuned **LLaMA** model, it can answer simple questions, generate code snippets, and assist with basic programming tasksâ€”all without an internet connection.

---

## ğŸš€ Features

- ğŸ§¾ Simple question answering  
- ğŸ§‘â€ğŸ’» Code generation (Python, C++, Java, etc.)  
- ğŸ”’ Fully offline â€“ No data leaves your system  
- âš¡ Fast and responsive â€“ Runs locally  
- ğŸ›  Easy to customize and extend

---

## ğŸ§  How It Works

This assistant uses a local instance of Metaâ€™s **LLaMA** model. You interact with it via a minimal interface (CLI or web), and it responds with answers or code based on your input prompt.

---

## ğŸ›  Installation

> ğŸ” **Note:** You must have access to the LLaMA model weights. This repo assumes you already have the model and tokenizer.

1. **Clone the repo**

```bash
git clone https://github.com/mani-0712/mini-offline-assistant.git
cd mini-offline-assistant
